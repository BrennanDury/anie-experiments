{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from data import load_navier_stokes_tensor, setup_dataloaders\n",
    "import time\n",
    "from training import training_epoch, evaluation_epoch\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Navierâ€“Stokes training script.\")\n",
    "parser.add_argument(\"--name\", type=str, default=\"test\")\n",
    "parser.add_argument(\"--data\", type=Path, default=Path(\"ns_data.mat\"), help=\"Path to the .mat dataset.\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "parser.add_argument(\"--batch-size\", type=int, default=8)\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "parser.add_argument(\"--weight-decay\", type=float, default=1e-4, help=\"Weight decay (L2 penalty) for Adam optimizer.\")\n",
    "parser.add_argument(\"--grad-clip-norm\", type=float, default=1.0, help=\"Gradient clipping norm (set to 0 to disable).\")\n",
    "parser.add_argument(\"--min-lr\", type=float, default=1e-9, help=\"Minimum learning rate for cosine annealing scheduler.\")\n",
    "parser.add_argument(\"--T-max\", type=int, default=101, help=\"Maximum number of iterations for cosine annealing scheduler.\")\n",
    "parser.add_argument(\"--n-timesteps\", type=int, default=11, help=\"Number of temporal frames to sample from the raw data (consistent with notebook).\")\n",
    "\n",
    "parser.add_argument(\"--share\", action=\"store_true\", help=\"Share weights between modules.\")\n",
    "parser.add_argument(\"--no-share\", dest=\"share\", action=\"store_false\", help=\"Don't share weights between modules.\")\n",
    "parser.set_defaults(share=True)\n",
    "\n",
    "parser.add_argument(\"--picard\", action=\"store_true\", help=\"Use Picard iterations.\")\n",
    "parser.add_argument(\"--no-picard\", dest=\"picard\", action=\"store_false\", help=\"Don't use Picard iterations.\")\n",
    "parser.set_defaults(picard=True)\n",
    "\n",
    "parser.add_argument(\"--d_model\", type=int, default=64)\n",
    "parser.add_argument(\"--nhead\", type=int, default=4)\n",
    "parser.add_argument(\"--dim_feedforward\", type=int, default=64)\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.1)\n",
    "parser.add_argument(\"--n_layers\", type=int, default=4)\n",
    "parser.add_argument(\"--n_modules\", type=int, default=4)\n",
    "parser.add_argument(\"--r\", type=float, default=0.5)\n",
    "\n",
    "# Encoder arguments\n",
    "parser.add_argument(\"--encoder-hidden-dim\", type=int, default=None, \n",
    "                    help=\"Hidden dimension for encoder (default: d_model - P)\")\n",
    "parser.add_argument(\"--encoder-hidden-ff\", type=int, default=128,\n",
    "                    help=\"Hidden feedforward dimension for encoder\")\n",
    "parser.add_argument(\"--patch_shape\", type=int, nargs=2, default=[4, 4],\n",
    "                    help=\"A token is a patch of size patch_shape\")\n",
    "\n",
    "# Decoder arguments\n",
    "parser.add_argument(\"--decoder-hidden-channels\", type=int, nargs=\"+\", default=[64, 256],\n",
    "                    help=\"Hidden channels for decoder MLP (excluding final output channel)\")\n",
    "\n",
    "parser.add_argument(\"--train-kind\", choices=[\"acausal\", \"one_step\", \"generate\"], default=\"acausal\",\n",
    "                    help=\"Pipeline kind to use during training\")\n",
    "parser.add_argument(\"--val-kind\", choices=[\"acausal\", \"one_step\", \"generate\"], default=\"acausal\",\n",
    "                    help=\"Pipeline kind to use during validation\")\n",
    "\n",
    "args = parser.parse_args(\"--epochs 1 --train-kind acausal --val-kind acausal\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf5c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created run directory: runs/test/run22\n"
     ]
    }
   ],
   "source": [
    "# Create directory structure\n",
    "Path(\"runs\").mkdir(exist_ok=True)\n",
    "base_dir = Path(\"runs/\" + args.name)\n",
    "base_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Find the next available run number\n",
    "run_num = 0\n",
    "while True:\n",
    "    run_dir = base_dir / f\"run{run_num}\"\n",
    "    if not run_dir.exists():\n",
    "        break\n",
    "    run_num += 1\n",
    "\n",
    "# Create the run directory\n",
    "run_dir.mkdir(exist_ok=True)\n",
    "print(f\"Created run directory: {run_dir}\")\n",
    "\n",
    "# Save hyperparameters/config\n",
    "config_dict = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'lr': args.lr,\n",
    "    'weight_decay': args.weight_decay,\n",
    "    'grad_clip_norm': args.grad_clip_norm,\n",
    "    'min_lr': args.min_lr,\n",
    "    'T_max': args.T_max,\n",
    "    'n_timesteps': args.n_timesteps,\n",
    "    'share': args.share,\n",
    "    'picard': args.picard,\n",
    "    'd_model': args.d_model,\n",
    "    'nhead': args.nhead,\n",
    "    'dim_feedforward': args.dim_feedforward,\n",
    "    'dropout': args.dropout,\n",
    "    'n_layers': args.n_layers,\n",
    "    'n_modules': args.n_modules,\n",
    "    'r': args.r,\n",
    "    'encoder_hidden_dim': args.encoder_hidden_dim,\n",
    "    'encoder_hidden_ff': args.encoder_hidden_ff,\n",
    "    'patch_shape': args.patch_shape,\n",
    "    'decoder_hidden_channels': args.decoder_hidden_channels,\n",
    "    'train_kind': args.train_kind,\n",
    "    'val_kind': args.val_kind,\n",
    "}\n",
    "np.save(run_dir / \"config.npy\", config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f3f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "init_conds, trajs = load_navier_stokes_tensor(args.data, n_timesteps=args.n_timesteps)\n",
    "init_conds = init_conds.to(device)\n",
    "trajs = trajs.to(device)\n",
    "\n",
    "train_loader, val_loader = setup_dataloaders(init_conds, trajs, batch_size=args.batch_size)\n",
    "P = 3\n",
    "N, T, H, W, Q = trajs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26087980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_block_mask_after(n_tokens, block_size):\n",
    "    idx = torch.arange(n_tokens, dtype=torch.long)\n",
    "    mask_after = block_size * ((idx // block_size) + 1) - 1\n",
    "    return mask_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd1b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import TrimTransformer, PatchwiseMLP, TimestepwiseMLP, PositionalEncoding, PositionalUnencoding\n",
    "from kind_wrappers import AcausalWrapper, OneStepWrapper, GenerateWrapper\n",
    "from architecture_wrappers import PicardIterations, ArbitraryIterations, make_weight_shared_modules, make_weight_unshared_modules\n",
    "from training import Pipeline\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e922b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture\n",
    "\n",
    "encoder_hidden_dim = args.encoder_hidden_dim if args.encoder_hidden_dim is not None else args.d_model - P\n",
    "\n",
    "encoder = PatchwiseMLP(dim=Q,\n",
    "                       hidden_dim=encoder_hidden_dim,\n",
    "                       out_dim=args.d_model-P,\n",
    "                       hidden_ff=args.encoder_hidden_ff,\n",
    "                       K=args.patch_shape,\n",
    "                       S=args.patch_shape)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Dummy forward pass to get shapes\n",
    "with torch.no_grad():\n",
    "    _, _, Hp, Wp, _ = encoder.forward(trajs[0, None, ...].to(device)).shape\n",
    "\n",
    "decoder = TimestepwiseMLP(in_shape=torch.Size([Hp, Wp, args.d_model-P]),\n",
    "                         layer_sizes=args.decoder_hidden_channels,\n",
    "                         out_shape=torch.Size([H, W, Q]))\n",
    "\n",
    "if args.train_kind == \"acausal\":\n",
    "    assert args.val_kind == \"acausal\"\n",
    "    time_width = args.n_timesteps + 1\n",
    "else:\n",
    "    time_width = args.n_timesteps\n",
    "n_tokens = time_width * Hp * Wp\n",
    "\n",
    "pos_enc = PositionalEncoding(time_width, Hp, Wp)\n",
    "pos_unenc = PositionalUnencoding(time_width, Hp, Wp)\n",
    "\n",
    "scale = 1 / n_tokens\n",
    "make_module = partial(TrimTransformer,\n",
    "                      d_model=args.d_model,\n",
    "                      nhead=args.nhead,\n",
    "                      dim_feedforward=args.dim_feedforward,\n",
    "                      dropout=args.dropout,\n",
    "                      n_layers=args.n_layers,\n",
    "                      scale=scale)\n",
    "\n",
    "if args.share:\n",
    "    modules = make_weight_shared_modules(make_module, n_modules=args.n_modules)\n",
    "else:\n",
    "    modules = make_weight_unshared_modules(make_module, n_modules=args.n_modules)\n",
    "\n",
    "if args.picard:\n",
    "    model = PicardIterations(modules, q=Q, r=args.r)\n",
    "else:\n",
    "    model = ArbitraryIterations(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce8f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a wrapper to handle the masking and whether or not to use the kv cache.\n",
    "\n",
    "patch_size = Hp * Wp\n",
    "mask = make_block_mask_after(n_tokens, patch_size).to(device)\n",
    "acausal_model = AcausalWrapper(model)\n",
    "one_step_model = OneStepWrapper(model, mask=mask)\n",
    "generate_model = GenerateWrapper(model)\n",
    "\n",
    "# Wrap all the components into a pipeline.\n",
    "acausal_pipeline = Pipeline(acausal_model, encoder, decoder, pos_enc, pos_unenc)\n",
    "one_step_pipeline = Pipeline(one_step_model, encoder, decoder, pos_enc, pos_unenc)\n",
    "generate_pipeline = Pipeline(generate_model, encoder, decoder, pos_enc, pos_unenc)\n",
    "acausal_pipeline.to(device)\n",
    "one_step_pipeline.to(device)\n",
    "generate_pipeline.to(device)\n",
    "\n",
    "pipelines = {\"acausal\": acausal_pipeline, \"one_step\": one_step_pipeline, \"generate\": generate_pipeline}\n",
    "train_pipeline = pipelines[args.train_kind]\n",
    "val_pipeline = pipelines[args.val_kind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83e83dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test | Epoch   1 | train loss: 0.109191 | val loss: 0.126126 | time: 64.23s\n",
      "\n",
      "Training completed! All files saved to: runs/test/run22\n",
      "Final train loss: 0.109191\n",
      "Final val loss: 0.126126\n",
      "Average epoch time: 64.23s\n",
      "Total training time: 64.23s\n"
     ]
    }
   ],
   "source": [
    "loss_fn = F.mse_loss\n",
    "optim = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(encoder.parameters()) + list(decoder.parameters()), lr=args.lr, weight_decay=args.weight_decay\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=args.T_max, eta_min=args.min_lr)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epoch_times = []\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_pipeline.train()\n",
    "    train_loss = training_epoch(train_loader, train_pipeline, args.train_kind, loss_fn, optim)\n",
    "    val_pipeline.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss   = evaluation_epoch(val_loader, val_pipeline, args.val_kind, loss_fn)\n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_time = epoch_end_time - epoch_start_time\n",
    "\n",
    "    # Append losses and times to tracking lists\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    epoch_times.append(epoch_time)\n",
    "    \n",
    "    print(f\"{args.name} | Epoch {epoch:3d} | train loss: {train_loss:.6f} | val loss: {val_loss:.6f} | time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    # Save losses and times as numpy arrays every epoch in run directory\n",
    "    np.save(run_dir / \"train_loss.npy\", np.array(train_losses))\n",
    "    np.save(run_dir / \"val_loss.npy\", np.array(val_losses))\n",
    "    np.save(run_dir / \"epoch_times.npy\", np.array(epoch_times))\n",
    "\n",
    "# Save model weights in run directory\n",
    "torch.save({\"state_dict\": model.state_dict()}, run_dir / \"model_weights.pt\")\n",
    "\n",
    "# Save final loss arrays and times in run directory\n",
    "np.save(run_dir / \"train_loss.npy\", np.array(train_losses))\n",
    "np.save(run_dir / \"val_loss.npy\", np.array(val_losses))\n",
    "np.save(run_dir / \"epoch_times.npy\", np.array(epoch_times))\n",
    "\n",
    "print(f\"\\nTraining completed! All files saved to: {run_dir}\")\n",
    "print(f\"Final train loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"Final val loss: {val_losses[-1]:.6f}\")\n",
    "print(f\"Average epoch time: {np.mean(epoch_times):.2f}s\")\n",
    "print(f\"Total training time: {np.sum(epoch_times):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ebb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
